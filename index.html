<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML+RDFa 1.0//EN" "http://www.w3.org/MarkUp/DTD/xhtml-rdfa-1.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:xsd="http://www.w3.org/2001/XMLSchema#"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
    xmlns:owl="http://www.w3.org/2002/07/owl#"
    xmlns:rsa="http://www.w3.org/ns/auth/rsa#"
    xmlns:cert="http://www.w3.org/ns/auth/cert#"
    xmlns:dcterms="http://purl.org/dc/terms/"
    xmlns:foaf="http://xmlns.com/foaf/0.1/"
    xmlns:v="http://www.w3.org/2006/vcard/ns#"
    xmlns:cc="http://creativecommons.org/ns#"
    xmlns:dbr="http://dbpedia.org/resource/"
    xmlns:dbp="http://dbpedia.org/property/"
    xmlns:sioc="http://rdfs.org/sioc/ns#"
    xmlns:wgs="http://www.w3.org/2003/01/geo/wgs84_pos#"
    xmlns:cal="http://www.w3.org/2002/12/cal/ical#"
    xmlns:org="http://www.w3.org/ns/org#"
    xmlns:biblio="http://purl.org/net/biblio#"
    xmlns:book="http://purl.org/NET/book/vocab#"
    xmlns:ov="http://open.vocab.org/terms/"
    xmlns:this="http://csarven.ca/statistical-linked-dataspace"
    xml:lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
        <title>Statistical Linked Dataspace</title>
        <meta name="description" content=""/>
        <link rel="stylesheet" type="text/css" media="all" href="display.css"/>
    </head>

    <body about="[this:]" typeof="foaf:Document sioc:Post biblio:Paper" class="hfeed journal">
        <div id="wrap">
            <div class="hentry">
                <h1 property="dcterms:title" class="entry-title">On the design of dataspaces for statistical Linked Data</h1>

                <div id="authors">
                    <dl>
                        <dt>Authors</dt>
                        <dd class="entry-author"><a about="[this:]" rel="dcterms:creator dcterms:publisher dcterms:contributor" href="http://csarven.ca/#i">Sarven Capadisli</a><sup><a href="#author_email_1">1</a></sup> <sup><a href="#author_org_a">a</a></sup></dd>
                    </dl>

                    <ul id="author_emails">
                        <li id="author_email_1"><sup>1</sup><a about="http://csarven.ca/#i" rel="foaf:mbox" href="mailto:info@csarven.ca" class="author_email">info@csarven.ca</a></li>
                    </ul>

                    <ul id="author_orgs">
                        <li id="author_org_a"><sup>a</sup><span about="http://csarven.ca/#i" rel="org:memberOf" resource="http://deri.ie/"/><a href="http://deri.ie/">Digital Enterprise Research Institute</a>, <a href="http://nuigalway.ie/">NUI, Galway</a>, Ireland</li>
                    </ul>
                </div>

                <div id="abstract" class="entry-summary">
                    <h2>Abstract</h2>
                    <p property="dcterms:abstract" datatype="">~The story here is ..</p>
                </div>

                <div property="dcterms:description" id="content" class="entry-content">
                    <div id="document-identifier">
                        <h2>ID</h2>
                        <p><code>http://csarven.ca/statistical-linked-dataspace</code></p>
                    </div>

                    <div id="keywords">
                        <h2>Keywords</h2>
                        <ul about="[this:]" rel="dcterms:subject">
                            <li><a resource="http://dbpedia.org/resource/Linked_Data" href="http://en.wikipedia.org/wiki/Linked_Data">Linked Data</a></li>
                            <li><a resource="http://dbpedia.org/resource/Data_modeling" href="http://en.wikipedia.org/wiki/Data_modeling">Data modeling</a></li>
                            <li><a resource="http://dbpedia.org/resource/Knowledge_management" href="http://en.wikipedia.org/wiki/Knowledge_management">Knowledge management</a></li>
                            <li><a resource="http://dbpedia.org/resource/Statistics" href="http://en.wikipedia.org/wiki/Statistics">Statistics</a></li>
                            <li><a resource="http://dbpedia.org/resource/Life_cycle" href="http://en.wikipedia.org/wiki/Life_cycle">Life cycle</a></li>
                        </ul>
                    </div>

                    <h2>Acknowledgements</h2>

                    <h2>Contents</h2>
                    <ul>
                        <li>...</li>
                    </ul>


                    <h2 id="introduction">Introduction</h2>
                    <h3 id="problem-statement">Problem statement</h3>
                    <p>Convenient management of dataspaces for statistical Linked Data remains to be costly and lacks integrated and automated tool support. The design considerations and requirements are therefore at the forefront for reasonable functionality of these dataspace platforms.</p>

                    <p>Access to statistical data, primarily in the public sector has exploded in recent years. While these initiatives provide new opportunities to get insights on societies, management of the dataspaces are consequently confronted with new challenges. As centralized dataspaces are now faced with more heterogeneous data collections, with varying quality, solutions which employ the Linked Data principles appear to be promising.</p>

                    <p>However, due to a range of technical challenges, development teams often face low-level repetitive data management tasks with partial tooling at their disposal. These challenges on the surface include: addressing data integration, synchronisation, and access. Within the context of statistical data, the expectations from these dataspaces is that, a Linked Data tool-chain is utilized, and the data is accessible to both humans as well as the machines.</p>


                    <h3 id="hypothesis">Hypothesis</h3>
                    <p>It is contended that the deployment of statistical Linked Data comes with a specific set of requirements. The degree in which the requirements are accomplished predetermines the dataspace's usefulness for data consumers. Therefore, the hypothesis of this document is if a specific set of requirements for building and managing dataspaces for statistical Linked Data is possible, and the development of missing parts to do some of the processes better by reducing cost and making the dataspace more useful.</p>

                    <h3 id="contributions">Contributions</h3>
                    <p>With preference to minimizing developer intervention wherever possible, the contributions herein are within the expectations of working in Linked Dataspace and providing read access to data respectively. The set of design considerations and requirements are derived from case studies in publishing CSO Ireland, Eurostat, and World Bank datasets. The contributions will identify required components, missing tools, and highlight best practices to create a statistical Linked Dataspace:</p>

                    <dl>
                        <dt>Required components</dt>
                        <dd>Identification of required components to create a dataspace.</dd>
                        <dt>GraphPusher</dt>
                        <dd>A tool to automate the process of building a dataspace through dataspace descriptions.</dd>
                        <dt>Linked Data Pages</dt>
                        <dd>A publishing framework that allows custom query results and HTML templates for resources.</dd>
                        <dt>Best practices</dt>
                        <dd>Summary of the lessons learned from development pitfalls, workarounds, and best practices on data retrieval, modeling, integration to publishing.</dd>
                    </dl>

                    <h3 id="outline">Thesis Outline</h3>




                    <h2 id="background">Background</h2>
                    <h3 id="dataspaces">Dataspaces</h3>
                    <p>The services that are typically offered in today's information managements systems have to deal with integration and administration of diverse data sources. An abstraction layer for the applications in these systems are considered as <q>Dataspaces</q> as proposed in <a href="http://dl.acm.org/citation.cfm?id=1107502"><cite>From Databases to Dataspaces</cite></a> article. What constitutes a dataspace is that, it would typically consist of a set of data sources with some relationships between them.</p>

                    <dl>
                        <dt>Participants and Relationships</dt>
                        <dd>The participating data sources in a dataspace can be databases, repositories, web services or software packages. The source data can be structured, semi-structured or unstructured, where some may be set to allow updates, yet others only for reading. Similarly, a dataspace may have different relationship models between its sources, with descriptions at any level of granularity, as well as information on data provenance.</dt>

                        <dt>Catalog and Browse</dt>
                        <dd>Dataspaces may include services to allow different modes of interaction with the data sources. Systems might simply provide services to support access to its catalogue in order to allow users to browse its inventory of data resources. Catalogues may have metadata about the resources such as their original source, used schemas, statistics on the data, creators, various timestamps, licensing, completeness and so forth. This type of provenance data provides a perspective for the users and administrators about the elements in the data sources, as well as assistance in reproduction and quality analysis.</dd>

                        <dt>Search and Query</dt>
                        <dd>One other type of service is meant for discovering data by way of searching and querying. The primary function for these services is to allow users to locate and extract particular information from the data sources. A search service offers relevant results to users based on keyword searches, as well as further exploration of the results. Its purpose is to provide a mechanism to deal with large collections of unfamiliar data using natural languages that users are familiar with. A query service in contrast, is meant to provide a structured way to retrieve or manipulate information in participating data sources. One important differentiating factor between searching and querying is that, a query service can let users formulate far more complex questions about the data and get answers to them.</dd>

                        <dt>Local storage and index</dt>
                        <dd>In order to give the data sources a home and to allow inquiry services, a storage and an accompanying index component is used. Local storages and indexes aid in creating efficient queries, precise access to data, and support for data recovery and availability. Indexes are invaluable in terms of identify information across data sources whether locally or references to objects in the real-world.</dd>

                        <dt>Discovery and extensions</dt>
                        <dd>Another type of dataspace service is the discovery component which is used for relating dataspace participants and consequently allow the system to provide better query results. This component would discover, identify and classify data sources and their content in order to easily locate and refer to items in the dataspace in the future. It is important for this component to monitor and allow an environment to update the schema mappings over time in order to accurately represent the dataspace's assets.<dd>

                        <dt>Pay-as-you-go</dt>
                        <dd>In creating semantic relationships between data sources, the involvement of users is usually focused on taking care of most beneficial efforts first. The system is expected to allow increment improvements based on the knowledge of the underlying data's structure, semantics and relationships between sources. Hence, a <em>pay-as-you-go</em> approach to data integration is employed in dataspaces as complete upfront integration is considered to be difficult and is not a required goal.</dd>
                    </dl>


                    <h3>Linked Data</h3>
                    <p>One manifestation of the Semantic Web vision is Linked Data. It is the a pragmatic approach to publishing structured data on the Web in order to discover related data from different sources. The original design principles was put forward by <a about="http://csarven.ca/#i" rel="foaf:knows" href="http://www.w3.org/People/Berners-Lee/card#i">Sir Tim Berners-Lee</a> in 2006 as follows:</p>

                    <blockquote about="http://www.w3.org/People/Berners-Lee/card#i" rel="dcterms:creator" href="http://www.w3.org/DesignIssues/LinkedData.html">
                        <ol>
                            <li>Use URIs as names for things</li>
                            <li>Use HTTP URIs so that people can look up those names.</li>
                            <li>When someone looks up a URI, provide useful information, using the standards (RDF*, SPARQL)</li>
                            <li>Include links to other URIs. so that they can discover more things.</li>
                        </ol>
                    </blockquote>

                    <dl>
                        <dt>HTTP URIs</dt>
                        <dd>In a nutshell, the use of URIs allows us to refer to things and concepts, whether they are real or imaginary, in an absolute way. In order to persistently make use of things, <cite>Sir Tim Berners-Lee</cite> proposed that <q href="http://www.w3.org/DesignIssues/Axioms.html#Universality2">any resource of significance should be given a URI</q>. By employing the widely adopted <code>http:</code> URI scheme, the idea for Linked Data sets off in terms of providing a representation for requested resources.</dd>

                        <dt>RDF data model</dd>
                        <dd>The key ingredient in the information that is returned to the user has to do with the model of the data in the response. Regardless of the syntax that is used, Resource Description Framework (RDF) is essentially an entity-relationship model that provides a way to make statements about the things in our reality. A statement contains three atomic parts, also known as a triple: the <em>subject</em> resource in which the statement is about, followed with a <em>property</em> which is a vocabulary term that describes the type of relationship it has to an <em>object</em> resource. Each of these components are typically represented using HTTP URIs, with the possibility of the object resource being a literal string. In mathematical terms, RDF is a directed, labeled graph, which conceptually depicts a graph of things. What makes this method to make claims about things worthwhile is the act of linking any two URIs together in a particular way. It fundamentally presents an opportunity to discover new resources in an uniform way, whether the resource is in local storage or somewhere else.</dd>

                        <dt>RDF vocabularies</dt>
                        <dd>In RDF triple statements, properties are vocabulary terms that are used to relate a subject to an object. As these resources are accessible via HTTP URIs, when dereferenced they provide a description for the term in use. Some of the well-known vocabularies that are used in Linked Data publishing include: Friend of a Friend (FOAF) to describe people and the things that they do; RDF Data Cube which is used to describe multi-dimensional statistical data; SDMX for the statistical information model; British reference periods, SKOS to describe controlled thesauri, classification schemes and taxonomies; DC Terms for general purpose metadata relations and; VoID to provide metadata on datasets.</dd>

                        <dt>SPARQL</dt>
                        <dd>SPARQL Protocol and RDF Query Language (SPARQL) is a protocol and a query language to retrieve and manipulate RDF data. It can be used to express queries across local and remote data sources, whether the data resides in RDF files or databases. SPARQL queries consist of RDF triple graph patterns written in a fashion similar to Turtle, and allows modifiers for the patterns. In the Linked Data scene, it is common to see publicly accessible SPARQL endpoints where queries are sent and received over HTTP. Federated queries can be written to compute results that span over different SPARQL endpoints on the Web.</dd>
                    </dl>

                    <p>The Linked Data efforts are concerned with publishing and querying all sorts of data that's interconnected in the form of a <em>Giant Global Graph</em>. Some of the motivations behind this is to uncover insights about societies, build smarter systems, making predictions, democratizing data for people, or to make better decisions.</p>


                    <h3 id="linked-statistics">Linked Statistics</h3>
                    <p>With the rise of special-purpose, domain-specific formats such as <a href="http://www.scb.se/Pages/List____314011.aspx">PC-Axis</a> [<a href="#r_1">1</a>] or <a href="http://sdmx.org/">Statistical Data and Metadata eXchange</a> (SDMX) [<a href="#r_2">2</a>], an ISO standard for exchanging and sharing statistical data and metadata among organizations, re-using statistical data has become more possible. However, with the complexity introduced by these formats, the barrier for consuming the data has raised as well. On the other hand, general-purpose formats such as Microsoft's Excel or CSV are very widely deployed and a number of tools and libraries in any kind of programming language one could possibly think of exist to process them. The down-side of these formats is equally obvious: as much of the high-quality annotations and metadata, that is, how to interpret the observations, is not or only partially captured, the data fidelity suffers. Even worse, using these formats, the data and metadata typically gets separated. With linked statistics, one can leverage the existing infrastructure as well as retaining metadata along with the data, yielding high data fidelity, consumable in a standardised, straight-forward way. However, the handling of statistical data as Linked Data requires particular attention in order to maintain its integrity and fidelity.</p>

					<p>Going beyond the operations of slicing, filtering and visualising statistical data typically requires out-of-band information to combine it with other kinds of data. Contextual information is usually not found in the statistical data itself. Using linked statistics, we are able to perform this data integration task in a more straight-forward way by leveraging the contextual information provided by the typed links between the data items of one data set to other datasets in the LOD cloud.</p>

                    <p>The <a href="http://www.w3.org/TR/vocab-data-cube/">RDF Data Cube vocabulary</a> is used to express multi-dimensional statistical data on the Web, and its data model is compatible with the cube model that underlies SDMX. Data cubes are in the nature of a hyper-cube such that multiple dimensions may be used to refer to a particular observation in the cube. Data cubes are characterised by their <em>dimensions</em>, which indicate what the observation is about with a set of properties; its <em>measures</em> to represent the phenomenon that is being observed with a value; and optionally with <em>attributes</em> which help interpret the measure values with a unit. Dimensions typically represent concepts, which are taken from a code list, and are highly valuable as they may used across data cubes by any consumer. Code lists, also known as classifications, are typically identified by using the <em>Simple Knowledge Organization System</em> (SKOS) vocabulary in RDF.</p>

					<p>What linked statistics provide, and in fact enable, are queries across datasets: given the dimensions are linked, one can learn from a certain observation's dimension value, other provided dimension values, enabling the automation of cross-dataset queries, hence cutting down integration costs and delivering results quicker.</p>

					<p>Organisations that are involved in publishing statistical Linked Data and establishing related methodologies and best practices include the <a href="http://data.gov.uk/">UK Government</a> [<a href="#r_3">3</a>], the National Institute of Statistics and Economic Studies (<dfn><abbr title="National Institute of Statistics and Economic Studies">INSEE</abbr></dfn>, France), the U.S. Bureau of Labour Statistics (<dfn><abbr title="Bureau of Labour Statistics">BLS</abbr></dfn>), and the European Environment Agency (<dfn><abbr title="European Environment Agency">EEA</abbr></dfn>). Statistics from many other sources are currently published not by the original statistics producer, but by third parties (universities, web technology companies etc.): U.S. Census 2000, Spanish Census, including historical microdata, EU election results, <a href="http://img.org/">International Monetary Fund</a> (<dfn><abbr title="International Monetary Fund">IMF</abbr></dfn>) commodity prices to name a few as well as the data from Central Statistics Office Ireland, Eurostat, and World Bank, which we will focus on in this paper.</p>


                    <h3>Lifecycles</h3>
                    <p>Summarize all of the lifecycles: http://www.w3.org/2011/gld/wiki/GLD_Life_cycle</p>
                    <p>Are they generic or government or statistical</p>
                    <ul>
                        <li>Hyland et al.</li>
                        <li>Hausenblas et al. http://linked-data-life-cycles.info/</li>
                        <li>Villazon-Terrazas et al.</li>
                        <li>DataLift vision</li>
                        <li>Linked Open Data Lifecycle (LOD2)</li>
                    </ul>


                    <h2 id="statistical-linked-dataspace">Statistical Linked Dataspace</h2>
                    <p>The idea of <em>Dataspaces</em> as discussed earlier was proposed without being tied to any particular set of technologies or types of data. It is a broad description for what constitutes a dataspace. For the moment, without diving into specific technologies, tooling, or data, possible parallels can be drawn between <em>Dataspaces</em> and dataspaces which follows the Linked Data design principles. Table [<a href="#table_dataspaces-to-linked-dataspaces">1</a>] presents a generalized view for the components and services in Linked Dataspaces.</p>

                    <table id="table_dataspaces-to-linked-dataspaces">
                        <caption><strong>Table 1.</strong> Dataspaces to Linked Dataspaces</caption>
                        <thead>
                            <tr><th>Dataspaces</th><th>Linked Dataspaces</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>Catalog</td><td>RDF dataset descriptions</td></tr>
                            <tr><td>Browse</td><td>HTML, RDF publishing framework</td></tr>
                            <tr><td>Local store and index</td><td>RDF files, stores, HTTP URIs</td></tr>
                            <tr><td>Search and Query</td><td>Free-text search and SPARQL</td></tr>
                            <tr><td>Discovery and relationships</td><td>Link discovery framework</td></tr>
                            <tr><td>Data management extensions</td><td>Semi-automatic data deployment</td></tr>
                            <tr><td>Metadata and provenance</td><td>RDF metadata vocabularies</td></tr>
                        </tbody>
                    </table>

                    <p>As Dataspaces are not attached to any specific list of data deployment services or practices, the Linked Dataspace can be seen as a narrower or a particular realization of a Dataspace. Having a dataspace that adheres to Linked Data principles is that, one of the forefront goals is to offer the data sources and some of its services in a way that the underlying data can be globally accessed and linked to by external data sources and applications.</p>

                    <p>The proposal here is that, with the assumption of publishing statistical data in a way that its components can be identified, discovered, and disseminated for numerous uses, a Linked Dataspace can be an ideal candidate. A statistical Linked Dataspace needs to identify resources and provide access to their descriptions, where such resources are in the nature of code lists, data cube observations, datasets and structures. Some of the specific challenges include: extraction of original data sources, transformations to RDF, and loading (ETL) to data storage services; creating global identifiers for the resources in its data catalogs; using vocabularies which are designed for modeling statistical data; offering services to the outside world such that its participating data sources can be browsed through; discovery via text searches and structured queries; and building interlinks with other data sources.</p>


                    <h2 id="requirements">Requirements</h2>
<!--
                    <p>Analysis of the original datasets (CSO Ireland, Eurostat, World Bank): What's available, why and what we are interested in (, what we need to prepare to access them?)</p>
                    <h3>Quantity: Huge amount of observations.. characteristics of the datasets (codelists.. in order to interpret observations).. how frequently are they updated (lower-upper bound)? Quality issues.. Provenance.. Not technically. Understanding / Analysis of the datasets.. How are they available (dumps, APIs)</h3>
-->
                    <p>A set of requirements to create a statistical Linked Dataspace are derived from the case studies of deploying CSO Ireland, Eurostat, and World Bank Linked Data. The requirements will be based on analysis of the original data sources, such as their characteristics in terms of quality, quantity, and update frequency.</p>

                    <p>A high-level inspection of published statistical data reveals itself as a collection of significant amounts of data, that's compiled over time by different parties. Naturally the quality of the data sources vary from one publisher to the next, as they try to cater to different publishing criteria. For instance, statistical data is often available in different data formats, with varying vocabularies and thesaurus that's specific to publisher's view about the data. In terms of consumption, one particular example is as follows: the usefulness of raw data that is available in CSV format may depend on the availability and quality of the metadata for the terms that are used in the file. The shape in which the data is available, sets the tone for the data consumer. The data consumers need to make decisions based on the amount of work involved to obtain and work with such data in their own space.</p>

                    <p>Therefore, it is reasonable to conclude that a number of decisions need to be made in order to prepare the dataspace for retrieval and reuse. A questionnaire along the following the lines can help determine the initial required actions to take:</p>
                    <ul>
                        <li>Who is the data publisher?</li>
                        <li>Which parties was involved in compiling the original data?</li>
                        <li>What data is being published?</li>
                        <li>What's the importance of that data?</li>
                        <li>What's the data license and terms of use?</li>
                        <li>How frequently is the data updated, if at all?</li>
                        <li>Which formats is the data available in?</li>
                        <li>Is the necessary tooling in place in order to work with the available formats?</li>
                        <li>Is there sufficient metadata?</li>
                        <li>Which languages is the data and metadata available in?</li>
                        <li>What granularity is the data in?</li>
                        <li>How big is the data?</li>
                        <li>Which access points is the data distributed through?</li>
                        <li>Are there special access privileges required to retrieve the data?</li>
                        <li>How many retrieval requests need to be made?</li>
                        <li>Are the data files syntactically well-formed?</li>
                        <li>Who are the people to contact?</li>
                        <li>Is the accuracy of the data indicated?</li>
                        <li>Are there different versions or variations of the data?</li>
                    </ul>



                    <h3 id="data-sources">Data sources</h3>
                    <h4 id="data-source_cso-ireland">CSO Ireland</h4>
                    <p>The <a href="http://cso.ie/">Central Statistics Office</a> (<dfn><abbr title="Central Statistics Office">CSO</abbr></dfn>) [<a href="#r_4">4</a>] is the official Irish agency responsible for collecting and disseminating statistics about Ireland. The main source of the statistical data for the CSO is the National Census that is scheduled to be held every five years. The data compiled by the CSO serve as a key input for decision-making in the Irish government and it informs its policies and programmes both at national and local levels.</p>

                    <p>The CSO publishes population statistics in several ways, none of which is particularly suited for direct reuse. The data is primarily available through the CSO's website, formatted for the purpose of display. The CSO offers access to raw demographic data in PC-Axis format for expressing multidimensional statistical data. CSO exposes raw data in an interactive data viewer provided by the <a href="http://www.beyond2020.com/">Beyond 20/20 software</a> [<a href="#r_5">5</a>] that allows to browse, sort and plot the data. It offers a way to export the data in XLS and CSV.</p>

                    <h4 id="data-source_eurostat">Eurostat</h4>
                    <p><a href="http://ec.europa.eu/eurostat">Eurostat</a> [<a href="#r_6">6</a>] is the statistical office of European Union with the aim to provide European Union statistical information in a way that can be comparable at European level. Statistical data collection is done by statistical authorities of each Member States. They verify and analyse the data before sending it to Eurostat. Eurostat's role is to consolidate the statistical data they receive from each Member States and ensure that they are comparable. Eurostat actually only provides harmonized statistical data using common statistical language.</p>

                    <p>Eurostat offers access to datasets using the <a href="http://epp.eurostat.ec.europa.eu/NavTree_prod/everybody/BulkDownloadListing">bulk download facility</a> [<a href="#r_7">6</a>]. The datasets are published by Eurostat in three different formats: TSV, DFT and SDMX. This makes it possible for users to import the data into the tool of their choice. A complete list of datasets which are published by Eurostat is made available through table of contents. Although there is no filtration on the different types of statistics provided by Eurostat, the datasets essentially cover statistical information along the following themes: general and regional statistics, economy and finance, population and social conditions, industry, trade and services, agriculture and fisheries, external trade, transport, environment and energy, and science and technology.</p>

                    <h4 id="data-source_world-bank">World Bank</h4>
                    <p>The <a href="http://worldbank.org/">World Bank</a> [<a href="#r_9">9</a>] is an international development organization that provides access to a comprehensive set of data about countries around the globe. The publicly available statistical data is collected from officially-recognized international sources, and consists of a wide array of observations on development indicators, financial statements, climate change, projects and operations.</p>

                    <p>The World Bank provides a free and open access to numerous datasets in their <a href="http://data.worldbank.org/data-catalog">data catalog</a> [<a href="#r_10">10</a>]. These datasets are available in one or more formats: XML, JSON, CSV, XLS; with additional geospatial data in SHP and KML, and supporting documentations in PDF. The World Bank APIs offers some of the datasets primarily in XML and JSON representations, whereas the rest of the formats are available as data dumps. In our use-case, the decision on which datasets to work with was based on several factors such as the importance of the dataset, its completeness, and the ease of converting it into an RDF representation. Hence, the following datasets from the World Bank's API was selected with the preference of working with XML:</p>

                    <ul>
                        <li><a href="http://data.worldbank.org/developers/climate-data-api">World Bank Climate Change</a> (<dfn><abbr title="World Bank Climate Change">WBCC</abbr></dfn>) [<a href="#r_11">11</a>] contains data from historical observations and future projections derived from global circulation models.</li>
                        <li><a href="http://data.worldbank.org/data-catalog/world-development-indicators">World Development Indicators</a> (<dfn><abbr title="World Development Indicators">WDI</abbr></dfn>) [<a href="#r_12">12</a>] contain various global development data on world view, people, the environment, the economy, states and markets, and global links. It includes national, regional and global estimates.</li>
                        <li><a href="https://finances.worldbank.org/">World Bank Finances</a> (<dfn><abbr title="World Bank Finances">WBF</abbr></dfn>) [<a href="#r_13">13</a>] cover Bank's investments, assets it manages on behalf of global funds, and the Bank's own financial statements.</li>
                        <li><a href="http://data.worldbank.org/data-catalog/projects-portfolio">World Bank Projects and Operations</a> (<dfn><abbr title="World Bank Projects and Operations">WBPO</abbr></dfn>) [<a href="#r_14">14</a>] provides information about the lending projects from 1947 to present along with links to publicly disclosed online documents.</li>
                    </ul>


                    <h3 id="data-retrieval">Data Retrieval</h3>
                    <h4 id="data-retrieval_cso-ireland">CSO Ireland</h4>
                    <p>Data from the 2006 Irish Census was retrieved manually, downloading each slice of small area population statistics individually via the export to Excel files from the <a href="http://beyond2020.cso.ie/census/ReportFolders/ReportFolders.aspx">CSO's instance of the Beyond 20/20</a> [<a href="#r_15">15</a>]. 14 datasets in CSV format in total of 8MB was manually retrieved using the interactive application by clicking on the access URLs.</p>

                    <h4 id="data-retrieval_eurostat">Eurostat</h4>
                    <p>There are approximately 6100 datasets published by Eurostat. Eurostat updates information about datasets as well as table of contents twice a day. The datasets holds statistics on daily, monthly, quarterly and annual basis. Therefore, certain datasets are updated daily and many datasets are updated on monthly basis. To keep Eurostat RDF datasets up to date, we've scheduled a cronjob, which runs a set of scripts on weekly basis. In order to avoid unnecessary RDF transformations of each dataset, we've only updated the changed datasets within the past week.</p>

                    <p>Along with the datasets, Eurostat also publishes Data Structure Definitions (<dfn><abbr title="Data Structure Definition">DSD</abbr></dfn>) about each dataset, as well as a set of dictionaries (code lists) which are shared among all datasets. Hence we take into consideration every type of information provided by Eurostat. The DSDs are published in XML format while the code lists are published in TSV format. Dataset is available in three different formats: TSV, DFT and SDMX. Given that the datasets, metadata and code lists each provide different type of information and is represented differently, we wrote Java programs to process XML and TSV formats of the metadata, dataset and code lists separately.</p>

                    <p>We have written different shell scripts which wrap each Java program and one main script which handles the whole process of data downloading and transformation by invoking other scripts.</p>

                    <p>Over 13000 HTTP GET requests was made to Eurostat to download raw datasets, DSDs and code lists, with a total of disk space of ~58GB.</p>

                    <h4 id="data-retrieval_world-bank">World Bank</h4>
                    <p>The World Bank datasets were collected by making requests to the World Bank API endpoints using the XML output format.</p>

                    <p>World Bank APIs was called ~150000 times to retrieve all of the WDI, WBF, WBCC, WBPO datasets, with a total disk space of ~20GB.</p>

                    <p>The data is retrieved at irregular periods - at least once a month - from the World Bank API endpoints. The retrieval act is partly based on new dataset announcements in World Bank mailing lists. Although the data retrieval and transformation phases are conducted by independent scripts, the commitment to retrieve and store the data is based on achieving the quality of the eventual RDF serialization. Therefore, Java and Bash scripts are manually executed to retrieve, in order to closely monitor abnormalities in the responses and account for necessary changes in the transformations.</p>



                    <h2 id="components">Components</h2>
                    <p>We have identified principle components for LDspaces, we talked about requirements.. now we provide a list of components to realize such space... technical part.</p>

                    <h3>Linked Dataspace components and services</h3>
                    <ul>
                        <li>Environment</li>
                        <li>Data retrieval</li>
                        <li>Data preprocessing</li>
                        <li>Data modeling</li>
                        <li>Data conversion</li>
                        <li>RDF store</li>
                        <li>SPARQL service</li>
                        <li>Loading RDF data to RDF store</li>
                        <li>RDF store optimization</li>
                        <li>Interlinking</li>
                        <li>Enrichment</li>
                        <li>User interface (publishing RDF, HTML, browsing)</li>
                        <li>Documentation (statistics)</li>
                        <li>Database metadata (descriptions, statistics)</li>
                        <li>Data dumps</li>
                        <li>Applications</li>
                    </ul>

                    <h2>Implementation of the Case Studies</h2>
                    <h3>Deployment Architectures</h3>

                    <h3>Data Retrieval and Preprocessing</h3>
                    <h4>Java / Linux shell</h4>



                    <h3>Data Modeling</h3>
                    <h4>Vocabularies</h4>
                    <h4>URL Patterns</h4>
                    <h4>Data Structure Definitions</h4>

                    <h3>Interlinking</h3>
                    <h4>Manual</h4>
                    <h4>LIMES (requires curation)</h4>

                    <h3>Enrichment</h3>
                    <h3>Provenance</h3>


                    <h3>Data Conversion</h3>
                    <h4>Java / Python / saxonb-xslt</h4>


                    <h3>Building RDF stores</h3>
                    <h4>Linux shell</h4>
                    <h4>GraphPusher</h4>


                    <h3>SPARQL Endpoint</h3>
                    <p>Public, Performance (optimization with TDB)</p>


                    <h2>Publication</h2>
                    <h3>VoID+SD</h3>
                    <ul>
                        <li>Dataset Metadata</li>
                        <li>Data Statistics (LODStats)</li>
                    </ul>

                    <h3>User Interface</h3>
                    <h4>Linked Data Pages</h4>


                    <h3>Applications</h3>
                    <h4>Building simple visualizations</h4>



                    <h3>Data dumps</h3>
                    <h3>License</h3>
                    <h3>Announcing the Datasets</h3>
                    <h3>Source Code</h3>





                    <h2>Conclusions</h2>

                    <div id="references">
                        <h2>References</h2>
                        <ol about="[this:]">
<!--
<li id="r_2">Ngonga Ngomo, A.-C.: <em>A Time-Efficient Hybrid Approach to Link Discovery</em>, The Sixth International Workshop on Ontology Matching, ISWC (2011), <a rel="dcterms:references" href="http://www.dit.unitn.it/~p2p/OM-2011/om2011_Tpaper1.pdf">http://www.dit.unitn.it/~p2p/OM-2011/om2011_Tpaper1.pdf">http://www.dit.unitn.it/~p2p/OM-2011/om2011_Tpaper1.pdf</a></li>
-->
                        </ol>
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>
